{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bert\n",
    "#import bert.run_classifier, bert.optimization, bert.tokenization\n",
    "from official.nlp.tools import tokenization\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import official.nlp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import sklearn.multioutput\n",
    "import tensorflow_text as text  # tf registers ops on import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import tensorflow_hub as hub\n",
    "import transformers\n",
    "\n",
    "from retrain_bert import settings\n",
    "from retrain_bert.preprocessor import load_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(\"official.nlp.modeling.models.bert_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9224011898040771, '+COCA'),\n",
       " (0.9198992848396301, 'CCOCA'),\n",
       " (0.9144041538238525, 'COCA~COLA'),\n",
       " (0.9136794805526733, '6COCA'),\n",
       " (0.9041818976402283, '*COCA'),\n",
       " (0.9007999897003174, '&COCA'),\n",
       " (0.8999505639076233, 'MCOCA'),\n",
       " (0.8999376893043518, 'C0CA'),\n",
       " (0.8985378742218018, 'COCA_COLA'),\n",
       " (0.8983514308929443, 'COCA-0LA')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = fasttext.load_model(str(settings.PROJECT_DIR / \"models/fasttext_model.bin\"))\n",
    "ft_model.get_nearest_neighbors(\"COCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = sklearn.linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(pd.read_csv(settings.PROJECT_DIR / \"data/train/train.csv\"))\n",
    "labels = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15073         CHOCO NEGRO ALM\n",
       "24025      AQUARIUS LLIM FRED\n",
       "18719      ANILLA ROMANA 400G\n",
       "17753     PALLA REUTILITZABLE\n",
       "5842           ESPINACS AMB C\n",
       "                 ...         \n",
       "36629     SALCHICHAS FRANFURT\n",
       "14725      CUÑA QUESO CYO 350\n",
       "145         SARDINA MED 25/40\n",
       "14053             TOMATE RAMA\n",
       "17743    SABÓ REN PLATS ULTRA\n",
       "Name: OcrValue, Length: 29642, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"OcrValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_vectors = train_data[\"OcrValue\"].apply(ft_model.get_word_vector)\n",
    "# train_vectors = pd.DataFrame.from_records(train_vectors.to_list()).values\n",
    "# train_vectors[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label_ids, labels_table=labels):\n",
    "    one_hot = np.zeros(len(labels_table))\n",
    "    one_hot[label_ids] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_data.drop(\"OcrValue\", axis=\"columns\").apply(encode_label, axis=\"columns\")\n",
    "train_targets = pd.DataFrame.from_records(train_targets.tolist()).values\n",
    "\n",
    "val_targets = val_data.drop(\"OcrValue\", axis=\"columns\").apply(encode_label, axis=\"columns\")\n",
    "val_targets = pd.DataFrame.from_records(val_targets.tolist()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(linear, train_vectors, train_targets, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear.fit(train_vectors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_conf = []\n",
    "level_start = 0\n",
    "level_end = 0\n",
    "for level in range(settings.DEEPEST_LEVEL):\n",
    "    level_end = level_start + len(labels.loc[level + 1])\n",
    "    labels_conf.append({\n",
    "        \"level\": level + 1,\n",
    "        \"start\": level_start,\n",
    "        \"end\": level_end,\n",
    "        \"num_classes\": len(labels.loc[level + 1])\n",
    "    })\n",
    "    level_start = level_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'level': 1, 'start': 0, 'end': 5, 'num_classes': 5},\n",
       " {'level': 2, 'start': 5, 'end': 16, 'num_classes': 11},\n",
       " {'level': 3, 'start': 16, 'end': 44, 'num_classes': 28},\n",
       " {'level': 4, 'start': 44, 'end': 75, 'num_classes': 31},\n",
       " {'level': 5, 'start': 75, 'end': 94, 'num_classes': 19}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_labels(labels, labels_table=labels):\n",
    "    \"\"\"Separates labels by levels\n",
    "    \n",
    "    Args:\n",
    "        labels (pd.Series): one hot encoded labels to separate\n",
    "    \"\"\"\n",
    "    level_start = 0\n",
    "    level_end = 0\n",
    "    for level in range(settings.DEEPEST_LEVEL):\n",
    "        level_end = level_start + len(labels_table.loc[level + 1])\n",
    "        #print(level, level_start, level_end, pred[:, level_start:level_end], true[:, level_start:level_end])\n",
    "        yield labels[:, level_start:level_end]\n",
    "        level_start = level_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def level_accuracy(pred, true, labels_table=labels):\n",
    "#     level_start = 0\n",
    "#     level_end = 0\n",
    "#     for level in range(settings.DEEPEST_LEVEL):\n",
    "#         level_end = level_start + len(labels_table.loc[level + 1])\n",
    "#         #print(level, level_start, level_end, pred[:, level_start:level_end], true[:, level_start:level_end])\n",
    "#         yield sklearn.metrics.accuracy_score(pred[:, level_start:level_end], true[:, level_start:level_end])\n",
    "#         level_start = level_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(level_accuracy(linear.predict(train_vectors), train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linears = [sklearn.linear_model.LogisticRegression(max_iter=15000, C=1) for _ in range(settings.DEEPEST_LEVEL)]\n",
    "\n",
    "# for model, targets in zip(linears, get_level_labels(train_targets)):\n",
    "#     break\n",
    "#     targets = np.argmax(targets, axis=1)\n",
    "#     max_label = np.max(targets)\n",
    "#     mask = targets != max_label\n",
    "#     model.fit(train_vectors[mask], targets[mask])\n",
    "#     print(model.score(train_vectors[mask], targets[mask]), mask.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "# tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "# model = transformers.TFBertModel.from_pretrained(\"bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceWithSynonims(tf.keras.layers.Layer):\n",
    "    def __init__(self, fasttext_model, replace_proba=.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fasttext_model = fasttext_model\n",
    "        self.replace_proba = replace_proba\n",
    "    \n",
    "    def __call__(self, sentences, training=False, **kwargs):\n",
    "        if not training:\n",
    "            return sentences\n",
    "        sentences = tf.strings.split(sentences, sep=\" \")\n",
    "        sentences = tf.map_fn(\n",
    "            lambda x: tf.cond(tf.random.uniform([]) < self.replace_proba,\n",
    "            lambda: self.__replace_with_a_synonim(x), lambda: x),\n",
    "            sentences\n",
    "        )\n",
    "        sentences = tf.strings.join(sentences, sep=\" \")\n",
    "        return sentences\n",
    "        \n",
    "    def __replace_with_a_synonim(self, word):\n",
    "        synonyms = self.fasttext_model.get_nearest_neighbors(word)\n",
    "        if len(synonyms) > 0:\n",
    "            return np.random.choice(synonyms)\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:10:31.099808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.152138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.152355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.153127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-30 18:10:31.153499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.153708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.153879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.665609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.665860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.666017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 18:10:31.666130: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-08-30 18:10:31.666220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4592 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-08-30 18:10:41.792754: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367248384 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "text_inputs = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "# TODO: reduce seq_length (128 is an overkill)\n",
    "# https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n",
    "data_augmentation = ReplaceWithSynonims(ft_model)\n",
    "#tokenizer_inputs = data_augmentation(text_inputs)\n",
    "lowercase = tf.strings.lower(text_inputs)\n",
    "tokenizer_inputs = lowercase\n",
    "tokenizer = hub.KerasLayer(\n",
    "   \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\",\n",
    "    #arguments={\"seq_length\": 32}\n",
    ")\n",
    "encoder_inputs = tokenizer(tokenizer_inputs)\n",
    "encoder = hub.KerasLayer(\n",
    "   \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\",\n",
    "    trainable=False\n",
    ")\n",
    "encoder_outputs = encoder(encoder_inputs)\n",
    "pooled_output = encoder_outputs[\"pooled_output\"]\n",
    "X = tf.keras.layers.Dense(settings.DEEPEST_LEVEL * settings.DEEPEST_LEVEL, activation=\"relu\")(pooled_output)\n",
    "X = tf.keras.layers.Dense(settings.DEEPEST_LEVEL * settings.DEEPEST_LEVEL, activation=\"relu\")(X)\n",
    "X = tf.keras.layers.Dense(settings.DEEPEST_LEVEL * settings.DEEPEST_LEVEL, activation=\"relu\")(X)\n",
    "X = tf.keras.layers.Dense(settings.DEEPEST_LEVEL * settings.DEEPEST_LEVEL, activation=\"relu\")(X)\n",
    "\n",
    "sequence_output = encoder_outputs[\"sequence_output\"]\n",
    "sequence_output = tf.keras.layers.Dropout(0.2)(sequence_output)\n",
    "sequence_output = tf.keras.layers.Conv1D(\n",
    "    128,\n",
    "    7,\n",
    "#    kernel_regularizer=L2(1e-3)\n",
    ")(sequence_output)\n",
    "sequence_output = tf.keras.layers.Flatten()(sequence_output)\n",
    "\n",
    "X = tf.keras.layers.Concatenate()([X, sequence_output])\n",
    "X = tf.keras.layers.Dropout(.2)(X)\n",
    "\n",
    "heads = []\n",
    "for level in range(settings.DEEPEST_LEVEL):\n",
    "    head = tf.keras.layers.Dense(\n",
    "        labels_conf[level][\"num_classes\"],\n",
    "        activation=\"softmax\",\n",
    "        name=f\"level_{level}\",\n",
    "        kernel_regularizer=L2(1e-5)\n",
    "    )(X)\n",
    "    X = tf.keras.layers.Concatenate()([X, head])\n",
    "    heads.append(head)\n",
    "\n",
    "model = tf.keras.Model(text_inputs, heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = encoder.resolved_object.vocab_file.asset_path.numpy() #The vocab file of bert for tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tfhub_modules/26807cff8c00c2271e22a6b31b83988c4bfe6528/assets/vocab.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = vocab_file.decode(\"utf-8\")\n",
    "vocab_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab = [line.strip() for line in f]\n",
    "\n",
    "hg_tokenizer = transformers.BertTokenizer(vocab_file, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='', vocab_size=119547, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 18:10:53.696349: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40/232 [====>.........................] - ETA: 4:46 - loss: 16.2956 - level_0_loss: 2.5159 - level_1_loss: 3.6579 - level_2_loss: 4.9872 - level_3_loss: 3.7860 - level_4_loss: 1.3464 - level_0_accuracy: 0.4754 - level_1_accuracy: 0.3168 - level_2_accuracy: 0.1764 - level_3_accuracy: 0.2217 - level_4_accuracy: 0.1348"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "    train_targets[:, labels_conf[l][\"start\"]:labels_conf[l][\"end\"]]\n",
    "    for l in range(settings.DEEPEST_LEVEL)\n",
    "]\n",
    "val_labels = [\n",
    "    val_targets[:, labels_conf[l][\"start\"]:labels_conf[l][\"end\"]]\n",
    "    for l in range(settings.DEEPEST_LEVEL)\n",
    "]\n",
    "\n",
    "train_sample_weigths = [np.ones(len(train_targets)) for _ in range(settings.DEEPEST_LEVEL)]\n",
    "for level, level_labels in enumerate(labels):\n",
    "    unknown_label = labels_conf[level][\"num_classes\"] - 1\n",
    "    train_sample_weigths[level][level_labels[:, unknown_label] == 1] = 0\n",
    "\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    train_data.OcrValue,\n",
    "    labels,\n",
    "    batch_size=128,\n",
    "    epochs=3,\n",
    "    sample_weight=train_sample_weigths,\n",
    "    validation_data=(val_data.OcrValue, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:hub.KerasLayer is trainable but has zero trainable weights.\n",
      "2022-08-30 17:55:42.864502: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:288] gpu_async_0 cuMemAllocAsync failed to allocate 12582912 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 21954560/6222970880\n",
      "2022-08-30 17:55:42.864525: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:293] Stats: Limit:                      4857987072\n",
      "InUse:                      5348182599\n",
      "MaxInUse:                   5348182599\n",
      "NumAllocs:                     8662956\n",
      "MaxAllocSize:                367248384\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-08-30 17:55:42.864568: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2022-08-30 17:55:42.864574: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1, 1\n",
      "2022-08-30 17:55:42.864578: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 179\n",
      "2022-08-30 17:55:42.864581: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 36\n",
      "2022-08-30 17:55:42.864585: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16, 3\n",
      "2022-08-30 17:55:42.864588: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 20, 5\n",
      "2022-08-30 17:55:42.864591: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 44, 5\n",
      "2022-08-30 17:55:42.864595: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 76, 5\n",
      "2022-08-30 17:55:42.864598: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 100, 20\n",
      "2022-08-30 17:55:42.864602: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 112, 5\n",
      "2022-08-30 17:55:42.864605: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 124, 5\n",
      "2022-08-30 17:55:42.864608: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 256, 5\n",
      "2022-08-30 17:55:42.864612: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 512, 5\n",
      "2022-08-30 17:55:42.864615: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 616, 1\n",
      "2022-08-30 17:55:42.864619: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 640, 1\n",
      "2022-08-30 17:55:42.864622: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1\n",
      "2022-08-30 17:55:42.864625: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1408, 1\n",
      "2022-08-30 17:55:42.864629: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2432, 1\n",
      "2022-08-30 17:55:42.864632: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2500, 15\n",
      "2022-08-30 17:55:42.864636: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3072, 336\n",
      "2022-08-30 17:55:42.864639: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3584, 1\n",
      "2022-08-30 17:55:42.864643: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3968, 1\n",
      "2022-08-30 17:55:42.864646: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 6144, 3\n",
      "2022-08-30 17:55:42.864649: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12288, 36\n",
      "2022-08-30 17:55:42.864653: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16384, 27\n",
      "2022-08-30 17:55:42.864656: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 32768, 1\n",
      "2022-08-30 17:55:42.864660: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 76800, 5\n",
      "2022-08-30 17:55:42.864663: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 118568, 5\n",
      "2022-08-30 17:55:42.864667: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 197620, 1\n",
      "2022-08-30 17:55:42.864670: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 312820, 8\n",
      "2022-08-30 17:55:42.864673: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 434764, 1\n",
      "2022-08-30 17:55:42.864677: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 478188, 1\n",
      "2022-08-30 17:55:42.864680: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 592840, 2\n",
      "2022-08-30 17:55:42.864683: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 688424, 8\n",
      "2022-08-30 17:55:42.864687: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 750956, 1\n",
      "2022-08-30 17:55:42.864690: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1106672, 1\n",
      "2022-08-30 17:55:42.864694: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1194416, 8\n",
      "2022-08-30 17:55:42.864697: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1225244, 1\n",
      "2022-08-30 17:55:42.864700: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1304248, 2\n",
      "2022-08-30 17:55:42.864704: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1572864, 3\n",
      "2022-08-30 17:55:42.864707: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1753584, 8\n",
      "2022-08-30 17:55:42.864710: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1944940, 8\n",
      "2022-08-30 17:55:42.864714: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2097152, 1\n",
      "2022-08-30 17:55:42.864717: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2252792, 2\n",
      "2022-08-30 17:55:42.864720: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2359296, 148\n",
      "2022-08-30 17:55:42.864724: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2752512, 5\n",
      "2022-08-30 17:55:42.864727: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3319904, 2\n",
      "2022-08-30 17:55:42.864730: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3675608, 2\n",
      "2022-08-30 17:55:42.864734: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 9437184, 72\n",
      "2022-08-30 17:55:42.864737: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12582912, 86\n",
      "2022-08-30 17:55:42.864740: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 25165824, 21\n",
      "2022-08-30 17:55:42.864744: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 50331648, 30\n",
      "2022-08-30 17:55:42.864747: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 367248384, 3\n",
      "2022-08-30 17:55:42.864767: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at einsum_op_impl.h:525 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,12,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[32,12,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n\t [[{{node transformer/layer_6/self_attention/einsum_1/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_115971]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/julius/lp/algori/retrain_bert/notebooks/modelling.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data\u001b[39m.\u001b[39;49mOcrValue, labels, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_data\u001b[39m.\u001b[39;49mOcrValue, val_labels))\n",
      "File \u001b[0;32m~/lp/algori/retrain_bert/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/lp/algori/retrain_bert/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,12,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n\t [[{{node transformer/layer_6/self_attention/einsum_1/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_115971]"
     ]
    }
   ],
   "source": [
    "for  layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(train_data.OcrValue, labels, batch_size=32, epochs=3, validation_data=(val_data.OcrValue, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 121s 2s/step\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict(val_data.OcrValue, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_ids = [\n",
    "    np.argmax(preds, axis=1) for preds in val_preds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 696s 3s/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(train_data.OcrValue, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_ids = [ np.argmax(labels, axis=1) for labels in val_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7844347738083189,\n",
       " 0.7338056680161943,\n",
       " 0.6173252279635258,\n",
       " 0.5221003301736075,\n",
       " 0.5364622760534948]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def level_specific_accuracy(preds, true, level):\n",
    "    return sklearn.metrics.accuracy_score(preds > 0.5, true, sample_weight=1 - true[:, -1])\n",
    "\n",
    "[level_specific_accuracy(preds, true, level) for level, preds, true in zip(range(settings.DEEPEST_LEVEL), val_preds, val_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9231495850482424,\n",
       " 0.9383265856950067,\n",
       " 0.9352953101770509,\n",
       " 0.8644007788989202,\n",
       " 0.8962358427714857]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[level_specific_accuracy(preds, true, level) for level, preds, true in zip(range(settings.DEEPEST_LEVEL), train_preds, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'level': 1, 'start': 0, 'end': 5, 'num_classes': 5},\n",
       " {'level': 2, 'start': 5, 'end': 16, 'num_classes': 11},\n",
       " {'level': 3, 'start': 16, 'end': 44, 'num_classes': 28},\n",
       " {'level': 4, 'start': 44, 'end': 75, 'num_classes': 31},\n",
       " {'level': 5, 'start': 75, 'end': 94, 'num_classes': 19}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linears = [sklearn.linear_model.LogisticRegression(max_iter=15000, C=1) for _ in range(settings.DEEPEST_LEVEL)]\n",
    "\n",
    "for model, targets in zip(linears, get_level_labels(train_targets)):\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    max_label = np.max(targets)\n",
    "    mask = targets != max_label\n",
    "    model.fit(train_vectors[mask], targets[mask])\n",
    "    print(model.score(train_vectors[mask], targets[mask]), mask.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ab8d4916c4a5da2793c6264341d61f20680658314f07d96ed1da85891f63f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
